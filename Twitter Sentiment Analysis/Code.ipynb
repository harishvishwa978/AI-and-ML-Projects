{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style = 'color:blue'> Problem statement : Perform sentiment analysis on Omnicron variant, data fetching directly from twitter</span>\n",
    "**Sentiment analysis is the process of identifying feelings and emotions expressed in words, through ML or AI**\n",
    "\n",
    "**Project Pipeline**\n",
    "\n",
    "Various steps in completing project are\n",
    "\n",
    "- **Import Necessary Dependencies**\n",
    "- **Read and Load the Dataset**\n",
    "- **Exploratory Data Analysis**\n",
    "- **Data Visualization of Target Variables**\n",
    "- **Data Preprocessing**\n",
    "- **Splitting our data into Train and Test Subset**\n",
    "- **Transforming Dataset using TF-IDF Vectorizer**\n",
    "- **Function for Model Evaluation**\n",
    "- **Model Building**\n",
    "- **Conclusion**\n",
    "\n",
    "- Here we have to get dataset directly fetched from twitter in realtime \n",
    "\n",
    "- performing realtime sentimental analysis on realtime data collecting from twitter\n",
    "- objective: perform sentiment analysis on realtime data collected from twitter \n",
    "\n",
    "                      \n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = 'color:blue'>   API (Application Programm Interface)</span>\n",
    "- Imagine you’re sitting at a table in a restaurant with a menu of choices to order from. The kitchen is the part of the “system” that will prepare your order. What is missing is the critical link to communicate your order to the kitchen and deliver your food back to your table. That’s where the waiter or API comes in. The waiter is the messenger – or API – that takes your request or order and tells the kitchen – the system – what to do. Then the waiter delivers the response back to you; in this case, it is the food.\n",
    "- API's are huge and are used everywhere\n",
    "- In simple words api stands as bridge for one to access the content in one's storage \n",
    "- There are many APIs on the Twitter platform that software developers can engage with, with the ultimate possibility to create fully automated systems which will interact with Twitter. While this feature could benefit companies by drawing insights from Twitter data\n",
    "\n",
    "   **From twitter api it's possible to extract many insights some are**\n",
    "- Tweets: searching, posting, filtering, engagement, streaming etc.\n",
    "- Accounts and users (Beta): account management, user interactions.\n",
    "- Media: uploading and accessing photos, videos and animated GIFs.\n",
    "- Trends: trending topics in a given location.\n",
    "- Geo: information about known places or places near a location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting twitter API keys**\n",
    "- If you don't already have an account, you can login with your normal Twitter credentials \n",
    "\n",
    "\n",
    "- follow the required prompts to create a developer project or click here <a href=\"https://dev.twitter.com/apps\" title=\"Twitter\">Click here</a>\n",
    "- Requesting the API key and secret via the Developer Portal causes Twitter to produce the following three things:\n",
    "1. API key (this is your 'consumer key')\n",
    "2. API secret key (this is your 'consumer secret')\n",
    "3. Bearer token\n",
    "- Next, visit the 'Authentication Tokens' area of the Developer Portal and generate an 'Access token & secret'. This will provide you with the following two items:\n",
    "1. Access token (this is your 'token key')\n",
    "2. Access token secret (this is your 'token secret')\n",
    "\n",
    "\n",
    "**Expected output**\n",
    "- the data fetched from twitter should undergo EDA for analyzing, cleaning, handling, manupulation, visualization..,etc\n",
    "- final output should show the sentiment of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  *Some tips to consider*\n",
    "\n",
    "- Machines can learn in every possible way so its always better to think out of the box\n",
    "    \n",
    "- Perform eda as diverse as possible and in contineous manner\n",
    "    \n",
    "- Try configuring with diffrent models to know how each model is diffrent with other ones \n",
    "    \n",
    "- Donot try to involve unneccesory codes and useless algorithms for dataset which just increases complexity\n",
    "    \n",
    "- Approaching problem statement in n number of ways helps us to find best one possible\n",
    "    \n",
    "- It's easier for one to understnd and manupulate if we have models as simple as possible \n",
    "    \n",
    "- When we have multiple models we can have multiple judgements based on models and their efficiencies\n",
    "    \n",
    "- Tuning helps increasing accuracy :)\n",
    "    \n",
    "- Have an idea of time consumed by the model, its better to have a model whose time management is good\n",
    "    \n",
    "- Spend good amount of time on analyzing dataset and draw as much insights as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tweepy is importantlibrary we will using to fetch data from twitter by api\n",
    "\n",
    "\n",
    "For more on tweepy documentation please click here <a href=\"https://docs.tweepy.org/en/stable/getting_started.html#hello-tweepy\" title=\"Tweepy\">Click here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtweepy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API credentials\n",
    "consumer_key = 'dYkvn5zjK6sVCzAbbxBPabOTr'\n",
    "consumer_secret = 'MVKWIcpIwDCs4xDUxWVBOo69pSPAN5fnDYJ7lVmJZQA8aYRy7O'\n",
    "access_token = '1768664721769836544-7IeakOeeJjzKVigOVVurVFdo0aEOU5'\n",
    "access_token_secret = 'KZK1g2gWclbsXO6glKaPEORzH9UQrnuogLxqqZakOfjel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Twitter API\n",
    "auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124momicron.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('omicron.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-2-3af5319c6eab>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-3af5319c6eab>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    tweets = fetch_tweets(\"Omnicron variant\", count=100)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " # Fetch real-time tweets\n",
    "    tweets = fetch_tweets(\"Omnicron variant\", count=100)\n",
    "\n",
    "    # Preprocess tweets and get sentiments\n",
    "    processed_tweets = [preprocess_tweet(tweet) for tweet in tweets]\n",
    "    sentiments = [get_sentiment(tweet) for tweet in processed_tweets]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({'Tweet': processed_tweets, 'Sentiment': sentiments})\n",
    "\n",
    "    # Print first few rows of DataFrame\n",
    "    print(\"Data Exploration and Visualization:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch real-time tweets\n",
    "def fetch_tweets(query, count=100):\n",
    "    tweets = []\n",
    "    for tweet in tweepy.Cursor(api.search, q=query, lang=\"en\", tweet_mode='extended').items(count):\n",
    "        tweets.append(tweet.full_text)\n",
    "    return tweets\n",
    "# Preprocess tweets\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)  # Remove RT (retweet) tags\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)  # Remove hyperlinks\n",
    "    tweet = re.sub(r'#', '', tweet)  # Remove '#' symbols\n",
    "    return tweet\n",
    "\n",
    "# Function to get sentiment polarity\n",
    "def get_sentiment(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    return 'positive' if analysis.sentiment.polarity > 0 else 'negative' if analysis.sentiment.polarity < 0 else 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Sentiment Distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Sentiment', data=df)\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "X = df['Tweet']\n",
    "y = df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Model Building - Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-Time Sentiment Analysis\n",
    "query = \"Omnicron variant\"\n",
    "real_time_tweets = fetch_tweets(query, count=10)\n",
    "real_time_processed_tweets = [preprocess_tweet(tweet) for tweet in real_time_tweets]\n",
    "real_time_tweets_tfidf = tfidf_vectorizer.transform(real_time_processed_tweets)\n",
    "real_time_sentiments = model.predict(real_time_tweets_tfidf)\n",
    "\n",
    "print(\"\\nReal-Time Sentiment Analysis:\")\n",
    "for i in range(len(real_time_tweets)):\n",
    "    print(f\"Tweet: {real_time_tweets[i]}\")\n",
    "    print(f\"Sentiment: {real_time_sentiments[i]}\")\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
